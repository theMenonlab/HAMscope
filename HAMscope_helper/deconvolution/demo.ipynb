{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b711e3",
   "metadata": {},
   "source": [
    "# Using Ring Deconvolution Microscopy (RDM)\n",
    "\n",
    "This is a notebook which will walk you through basics of rdmpy.\n",
    "\n",
    "Interested in some background on these methods? Check out the [paper](https://arxiv.org/abs/2206.08928).\n",
    "\n",
    "The data we use in this notebook comes from the [UCLA Miniscope](http://miniscope.org/index.php/Main_Page).\n",
    "\n",
    "Refer to the other notebooks in the repository for replication of the experiments in the paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ce0f1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Here we import some necessary packages/helper functions for the demo, including the star of the show: rdmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ae1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!export CUDA_VISIBLE_DEVICES=0,1,2,3 # REPLACE this line according to your GPUs\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\" # REPLACE this line according to your GPUs\n",
    "\n",
    "import rdmpy\n",
    "\n",
    "# here are some basics we will need for the demo\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "# Fill this in according to your computer, we highly recommend using a GPU.\n",
    "# We needed ~20GB of GPU memory to run at full resolution (1024 x 1024).\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    \n",
    "print('Using ' +str(device) + ' for computation')\n",
    "\n",
    "def center_crop(img, des_shape, center=None):\n",
    "    if center is None:\n",
    "        center = (img.shape[0] // 2, img.shape[1] // 2)\n",
    "    left, right, up, down = (\n",
    "        center[1] - des_shape[1] // 2,\n",
    "        center[1] + int(np.round(des_shape[1] / 2)),\n",
    "        center[0] - des_shape[0] // 2,\n",
    "        center[0] + int(np.round(des_shape[0] / 2)),\n",
    "    )\n",
    "    img = img[up:down, left:right]\n",
    "    return img\n",
    "\n",
    "def crop(img, c):\n",
    "    return img[c:-c,c:-c]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5baddb",
   "metadata": {},
   "source": [
    "## One-time Calibration\n",
    "\n",
    "The first step in the RDM pipeline is to calibrate your microscope. This is very similar to measuring a point spread function for deconvolution. The only difference is now you take a single image of randomly-placed point sources. We visualize one such calibration image from the Miniscope in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807003c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 512 # Pick this according to how big of an image you want to deblur. Reduce if memory errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02692256",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_image = np.array(Image.open('test_images/calibration_image.tif'))\n",
    "#calibration_image = np.array(Image.open('/media/al/hs_results/20250701_AI/20250706_results/20250425_0gan_single_reg_hs_100_points_512/test_latest/images/hs_gen_99.tif'))\n",
    "#background = np.array(Image.open('/media/al/Extreme SSD/20250425_results/results/20250705/results/20250425_0gan_single_reg_hs_100_points/test_latest/average_stack.tif'))\n",
    "\n",
    "#calibration_image = calibration_image - 1 * background\n",
    "#calibration_image = np.clip(calibration_image, 0, None)  # Remove negative values\n",
    "\n",
    "import tifffile\n",
    "calibration_image = tifffile.imread('/media/al/20250701_AI/hs_results/20250706_results/20250425_0gan_single_reg_hs_100_points_512/test_latest/images/hs_gen_99.tif')\n",
    "calibration_image = calibration_image[20, :, :]\n",
    "\n",
    "\n",
    "print('Calibration image shape: ', calibration_image.shape)\n",
    "\n",
    "plt.imshow(calibration_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b866e",
   "metadata": {},
   "source": [
    "To calibrate, just input this image into the `calibrate` function. This will give back Seidel coefficients and synthetic PSFs. These characterize the system and can be directly used to blur/deblur any image taken from the microscope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300cd192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys_params = {\"NA\": 0.5}\n",
    "seidel_coeffs = rdmpy.calibrate_rdm(calibration_image, dim=512, device=device, show_psfs=True, get_psfs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823b2fc",
   "metadata": {},
   "source": [
    "## Simulating blur with ring convolution\n",
    "Now that we have calibrated the system, we can simulate the spatially-varying blur using ring convolution. Normally this process would take over an hour, even for 512x512 image! Check out how fast it is with ring convolution. If you want to speed it up even more or reduce memory, try setting patch_size to something like 8 or 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f136b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_data = rdmpy.get_rdm_psfs(seidel_coeffs, dim=dim, model='lri', device=device) #optional set patch_size=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/al/20250701_AI/20250706_results/20250425_0gan_single_reg_hs_100_points_512/test_latest/99point_stack_ch20.pt'\n",
    "\n",
    "# Save the variables.\n",
    "def save_variables(seidel_coeffs, psf_data, path):\n",
    "    torch.save({'seidel_coeffs': seidel_coeffs, 'psf_data': psf_data}, path)\n",
    "\n",
    "# Example use: \n",
    "    \n",
    "save_variables(seidel_coeffs, psf_data, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a10434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdmpy\n",
    "\n",
    "# here are some basics we will need for the demo\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io, color, img_as_ubyte\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import tifffile\n",
    "\n",
    "# Fill this in according to your computer, we highly recommend using a GPU.\n",
    "# We needed ~20GB of GPU memory to run at full resolution.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    \n",
    "print('Using ' +str(device) + ' for computation')\n",
    "\n",
    "# Load the variables.\n",
    "def load_variables(path):\n",
    "    loaded_data = torch.load(path)\n",
    "    return loaded_data['seidel_coeffs'], loaded_data['psf_data']\n",
    "\n",
    "path = '/media/al/20250701_AI/hs_results/20250706_results/20250425_0gan_single_reg_hs_100_points_512/test_latest/99point_stack.pt'\n",
    "\n",
    "seidel_coeffs, psf_data = load_variables(path)# Determine the correct angular dimension size from psf_roft\n",
    "#print(seidel_coeffs.shape)\n",
    "dim = 512\n",
    "\n",
    "print(psf_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f85c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a test image\n",
    "#measurement = plt.imread('test_images/baboon.png')\n",
    "measurement = plt.imread('/media/al/Extreme SSD/20250701_usaf/20250425_0gan_single_reg_hs_usaf/test_latest/images/hs_gen_0-0020.png')\n",
    "measurement = tifffile.imread('/media/al/Extreme SSD/20250701_usaf/20250425_0gan_single_reg_hs_usaf/test_latest/images/hs_gen_0.tif')\n",
    "print('Measurement shape: ', measurement.shape)\n",
    "measurement = measurement[10, :, :] \n",
    "measurement = measurement/measurement.max()\n",
    "plt.imshow(measurement, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218aa57",
   "metadata": {},
   "source": [
    "## Deblurring time: Ring deconvolution\n",
    "Now that we have a blurry, noisy measurement and the Seidel PSFs from the calibration procedure, we can run our main algorithm Ring deconvolution! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6df7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop to get rid of edge artifacts caused by finite size PSF\n",
    "c = 10\n",
    "\n",
    "#now deblur with ring deconvolution\n",
    "rd_recon = rdmpy.ring_deconvolve(measurement, psf_data, iters=150, device=device, process=False) #optional set patch_size=16\n",
    "#rd_recon = rdmpy.ring_deconvolve(measurement, psf_data, iters=200, lr=5e-2, tv_reg=1e-11, l2_reg=1e-6, opt_params={\"upper_projection\": True}, process=True, hot_pixel=True, device=device)\n",
    "\n",
    "plt.imsave('/media/al/Extreme SSD/20250701_usaf/deconvolution_20250706/rd_100_ch20_0.png', rd_recon, cmap='gray')\n",
    "plt.imshow(crop(rd_recon,c), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a224f77",
   "metadata": {},
   "source": [
    "## Faster alternative: DeepRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407b3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now with DeepRD, an even faster solution!\n",
    "deeprd_recon = rdmpy.deeprd(measurement, seidel_coeffs, device=device, process=False)\n",
    "\n",
    "plt.imsave('/media/al/Extreme SSD/20250701_usaf/deconvolution_20250706/deeprd_100_ch20_0.png', deeprd_recon, cmap='gray')\n",
    "plt.imshow(crop(deeprd_recon,c), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafac98",
   "metadata": {},
   "source": [
    "## Alternative methods: Seidel deconvolution\n",
    "Sometimes the system is sufficiently spatially-invariant. Even so RDM can help by using the synthetic Seidel PSFs for noiseless deconvolution. There is also a blind version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we get the center PSF from our fitted Seidel coefficients\n",
    "center_psf = rdmpy.get_rdm_psfs(seidel_coeffs, dim, model='lsi', device=device)\n",
    "\n",
    "# Now we can do standard deconvolution\n",
    "deconv = rdmpy.deconvolve(measurement, center_psf, device=device, process=False)\n",
    "\n",
    "plt.imsave('/media/al/Extreme SSD/20250701_usaf/deconvolution_20250706/wiener_100_ch20_newer.png', deconv, cmap='gray')\n",
    "plt.imshow(deconv, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548ff9d",
   "metadata": {},
   "source": [
    "## Batch Processing: Generate Calibration Files for All 30 Channels\n",
    "\n",
    "This code block will process calibration images to generate calibration.pt files for all 30 channels. Each channel will be calibrated separately and saved as a .pt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd896b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tifffile\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import rdmpy\n",
    "\n",
    "\n",
    "# Configuration\n",
    "calibration_folder = '/media/al/20250701_AI/hs_results/20250706_results/20250425_0gan_single_reg_hs_100_points_512/test_latest/images/'\n",
    "calibration_pattern = 'hs_gen_99.tif'  # Pattern for calibration files\n",
    "output_folder = '/media/al/20250701_AI/calibration_files/'\n",
    "dim = 512\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Find calibration files\n",
    "calibration_files = glob.glob(os.path.join(calibration_folder, calibration_pattern))\n",
    "print(f\"Found {len(calibration_files)} calibration files\")\n",
    "\n",
    "# Process each calibration file\n",
    "for cal_file in calibration_files:\n",
    "    print(f\"\\nProcessing: {cal_file}\")\n",
    "    \n",
    "    # Load the calibration image stack\n",
    "    calibration_stack = tifffile.imread(cal_file)\n",
    "    print(f\"Calibration stack shape: {calibration_stack.shape}\")\n",
    "    \n",
    "    # Process first 30 channels\n",
    "    num_channels = min(30, calibration_stack.shape[0])\n",
    "    \n",
    "    for channel in range(num_channels):\n",
    "        print(f\"Processing channel {channel + 1}/{num_channels}\")\n",
    "        \n",
    "        # Extract single channel\n",
    "        calibration_image = calibration_stack[channel, :, :]\n",
    "        \n",
    "        # Generate unique filename for this channel\n",
    "        base_name = Path(cal_file).stem\n",
    "        output_file = os.path.join(output_folder, f\"{base_name}_ch{channel:02d}_calibration.pt\")\n",
    "        \n",
    "        # Skip if already exists\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"  Channel {channel} already exists, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Calibrate the system for this channel\n",
    "            # Note: Using show_psfs=True to avoid the 'psfs_gt' error in rdmpy\n",
    "            seidel_coeffs = rdmpy.calibrate_rdm(calibration_image, dim=dim, device=device, show_psfs=True, get_psfs=False)\n",
    "            \n",
    "            # Get the center PSF for spatially invariant deconvolution\n",
    "            center_psf = rdmpy.get_rdm_psfs(seidel_coeffs, dim, model='lsi', device=device)\n",
    "            \n",
    "            # Save calibration data\n",
    "            torch.save({\n",
    "                'seidel_coeffs': seidel_coeffs,\n",
    "                'center_psf': center_psf,\n",
    "                'channel': channel,\n",
    "                'dim': dim,\n",
    "                'calibration_file': cal_file\n",
    "            }, output_file)\n",
    "            \n",
    "            print(f\"  Saved calibration for channel {channel} to {output_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing channel {channel}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "print(\"\\nBatch calibration processing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa6631",
   "metadata": {},
   "source": [
    "## Batch Processing: Wiener Deconvolution for TIF Stacks\n",
    "\n",
    "This code block will process a folder of TIF stack images, performing spatially invariant Wiener deconvolution on each channel using the corresponding calibration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec136335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tifffile\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import rdmpy\n",
    "\n",
    "# Configuration\n",
    "measurement_folder = '/media/al/Extreme SSD/20250701_usaf/20250425_0gan_single_reg_hs_usaf/test_latest/images' \n",
    "measurement_folder = '/media/al/Extreme SSD/20250425_results/results/20250704/results/20250425_0gan_single_reg_hs_3/test_latest/images'\n",
    "measurement_folder = '/media/al/Extreme SSD/20250701_usaf/lower_res/results/20250425_0gan_single_reg_hs_usaf/20250425_0gan_single_reg_hs/test_latest/images'\n",
    "measurement_folder = '/media/al/Extreme SSD/20250701_usaf/20250708_results/20250425_0gan_single_reg_hs_usaf/test_latest/images'\n",
    "measurement_folder = '/media/al/Extreme SSD/20250425_results/results/misc_test_dataset_layernorm/results/20250425_0gan_single_reg_hs_suberine/test_latest/images'\n",
    "calibration_folder = '/media/al/20250701_AI/calibration_files/'  # Where calibration .pt files are stored\n",
    "output_folder = '/media/al/Extreme SSD/20250425_results/results/misc_test_dataset_layernorm/results/20250425_0gan_single_reg_hs_suberine/test_latest/deconvolved_images'\n",
    "measurement_pattern = '*.tif'  # Pattern for measurement files\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Find measurement files\n",
    "measurement_files = glob.glob(os.path.join(measurement_folder, measurement_pattern))\n",
    "print(f\"Found {len(measurement_files)} measurement files\")\n",
    "\n",
    "# Process each measurement file\n",
    "for meas_file in measurement_files:\n",
    "    print(f\"\\nProcessing: {meas_file}\")\n",
    "    \n",
    "    # Load the measurement image stack\n",
    "    measurement_stack = tifffile.imread(meas_file)\n",
    "    print(f\"Measurement stack shape: {measurement_stack.shape}\")\n",
    "    \n",
    "    # Process first 30 channels\n",
    "    num_channels = min(30, measurement_stack.shape[0])\n",
    "    \n",
    "    # Prepare output stack\n",
    "    deconv_stack = np.zeros_like(measurement_stack[:num_channels])\n",
    "    \n",
    "    for channel in range(num_channels):\n",
    "        print(f\"Processing channel {channel + 1}/{num_channels}\")\n",
    "        \n",
    "        # Extract single channel\n",
    "        measurement_stack = measurement_stack /measurement_stack.max()  # Normalize\n",
    "        measurement_image = measurement_stack[channel, :, :]\n",
    "\n",
    "        # Find corresponding calibration file\n",
    "        # Assuming calibration files are named like: hs_gen_99_ch00_calibration.pt\n",
    "        cal_file = os.path.join(calibration_folder, f\"hs_gen_99_ch{channel:02d}_calibration.pt\")\n",
    "        #cal_file = os.path.join(calibration_folder, f\"hs_gen_99_ch{20}_calibration.pt\")\n",
    "\n",
    "        \n",
    "        if not os.path.exists(cal_file):\n",
    "            print(f\"  Calibration file not found for channel {channel}: {cal_file}\")\n",
    "            # Use original image if no calibration available\n",
    "            deconv_stack[channel] = measurement_image\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Load calibration data\n",
    "            cal_data = torch.load(cal_file, map_location=device)\n",
    "            center_psf = cal_data['center_psf']\n",
    "            \n",
    "            # Perform Wiener deconvolution\n",
    "            deconv_result = rdmpy.deconvolve(measurement_image, center_psf, device=device, process=False)\n",
    "            \n",
    "            # Store result\n",
    "            deconv_stack[channel] = deconv_result.cpu().numpy() if torch.is_tensor(deconv_result) else deconv_result\n",
    "            \n",
    "            print(f\"  Successfully deconvolved channel {channel}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing channel {channel}: {str(e)}\")\n",
    "            # Use original image if deconvolution fails\n",
    "            deconv_stack[channel] = measurement_image\n",
    "            continue\n",
    "    \n",
    "    # Save deconvolved stack\n",
    "    base_name = Path(meas_file).stem\n",
    "    output_file = os.path.join(output_folder, f\"{base_name}_deconvolved.tif\")\n",
    "    \n",
    "    # Save as 32-bit float to preserve dynamic range\n",
    "    tifffile.imwrite(output_file, deconv_stack.astype(np.float32))\n",
    "    print(f\"Saved deconvolved stack to: {output_file}\")\n",
    "    \n",
    "    # Optional: Save individual channels as PNG for visualization\n",
    "    png_folder = os.path.join(output_folder, f\"{base_name}_channels\")\n",
    "    os.makedirs(png_folder, exist_ok=True)\n",
    "    \n",
    "    for channel in range(num_channels):\n",
    "        png_file = os.path.join(png_folder, f\"channel_{channel:02d}.png\")\n",
    "        plt.imsave(png_file, deconv_stack[channel], cmap='gray')\n",
    "    \n",
    "    print(f\"Saved individual channel PNGs to: {png_folder}\")\n",
    "\n",
    "print(\"\\nBatch deconvolution processing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902aed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "\n",
    "# Configuration - matching visualize_models_misc.py exactly\n",
    "clip_min = 0.0\n",
    "clip_max = 0.6  # Adjust this to match your data range (0.03, 0.2, 0.3, etc.)\n",
    "selected_channels = [0, 12, 23]  # Channels 700, 600, 500 nm (adjust as needed)\n",
    "\n",
    "# Folders to process - both original and intensity preserved deconvolution results\n",
    "folders_to_process = [\n",
    "    '/media/al/Extreme SSD/20250425_results/results/misc_test_dataset_layernorm/results/20250425_0gan_single_reg_hs_suberine/test_latest/deconvolved_images',\n",
    "]\n",
    "\n",
    "def apply_viridis_colormap_and_clipping(img_data, output_dir, base_name, method_suffix=\"\"):\n",
    "    \"\"\"Apply viridis colormap and clipping exactly like visualize_models_misc.py\"\"\"\n",
    "    try:\n",
    "        # Check if image has enough channels for hyperspectral processing\n",
    "        if img_data.ndim == 3 and img_data.shape[0] > 3:\n",
    "            # Format is [channels, height, width]\n",
    "            for i, channel in enumerate(selected_channels):\n",
    "                if channel < img_data.shape[0]:\n",
    "                    selected_channel_data = img_data[channel, :, :]\n",
    "                    \n",
    "                    # Normalize data using min/max clipping (EXACT same as visualize_models_misc.py)\n",
    "                    clipped_data = np.clip(selected_channel_data, clip_min, clip_max)\n",
    "                    channel_norm = ((clipped_data - clip_min) / (clip_max - clip_min) * 255).astype(np.uint8)\n",
    "                    \n",
    "                    # Apply viridis colormap (EXACT same as visualize_models_misc.py)\n",
    "                    colored_img = cm.viridis(channel_norm)\n",
    "                    colored_img = (colored_img[:, :, :3] * 255).astype(np.uint8)\n",
    "                    \n",
    "                    # Save the image with same naming convention\n",
    "                    output_path = os.path.join(output_dir, f\"{base_name}_ch{channel}_clip[{clip_min},{clip_max}]{method_suffix}.png\")\n",
    "                    img = Image.fromarray(colored_img)\n",
    "                    img.save(output_path)\n",
    "                    print(f\"Saved visualization: {base_name}_ch{channel}_clip[{clip_min},{clip_max}]{method_suffix}.png\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Not enough channels for hyperspectral processing (shape: {img_data.shape})\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error applying colormap: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Process both deconvolution result folders\n",
    "for folder_path in folders_to_process:\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nProcessing folder: {folder_path}\")\n",
    "    \n",
    "    # Determine method suffix based on folder name\n",
    "    if \"intensity_preserved\" in folder_path:\n",
    "        method_suffix = \"_intensity_preserved\"\n",
    "    else:\n",
    "        method_suffix = \"_original\"\n",
    "    \n",
    "    # Create visualization output directory\n",
    "    vis_output_dir = os.path.join(folder_path, \"viridis_visualizations\")\n",
    "    os.makedirs(vis_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all deconvolved TIF files\n",
    "    tif_files = glob.glob(os.path.join(folder_path, \"*_deconvolved.tif\"))\n",
    "    \n",
    "    for tif_file in tif_files:\n",
    "        print(f\"Visualizing: {tif_file}\")\n",
    "        \n",
    "        try:\n",
    "            # Load the deconvolved image stack\n",
    "            img_data = tifffile.imread(tif_file)\n",
    "            print(f\"Loaded image with shape: {img_data.shape}\")\n",
    "            \n",
    "            # Extract base name\n",
    "            base_name = Path(tif_file).stem.replace(\"_deconvolved\", \"\")\n",
    "            \n",
    "            # Apply viridis colormap and clipping (same as visualize_models_misc.py)\n",
    "            apply_viridis_colormap_and_clipping(img_data, vis_output_dir, base_name, method_suffix)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {tif_file}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nVisualization processing completed!\")\n",
    "print(f\"Results saved to 'viridis_visualizations' folders in both deconvolution output directories\")\n",
    "print(f\"Using clipping range: [{clip_min}, {clip_max}]\")\n",
    "print(f\"Selected channels: {selected_channels}\")\n",
    "print(f\"Colormap: viridis (same as visualize_models_misc.py)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7744de",
   "metadata": {},
   "source": [
    "## Alternate methods: Blind deconvolution\n",
    "By co-optimizing the spherical Seidel coefficient with the reconstruction we can perform calibration-free deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1419f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, we don't use the PSF data or Seidel coefficients; this method only requires a blurry image.\n",
    "deconv_blind = rdmpy.blind(measurement, device=device, process=True, balance=3e-4)\n",
    "\n",
    "print('Pretty close to the fitted coefficient: ', seidel_coeffs[0].cpu())\n",
    "plt.imsave('/media/al/Extreme SSD/20250701_usaf/deconvolution_20250706/blind_3e-4.png', deconv_blind, cmap='gray')\n",
    "plt.imshow(crop(deconv_blind,c), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ce2b6c",
   "metadata": {},
   "source": [
    "Batch blind DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tifffile\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import rdmpy\n",
    "\n",
    "# Configuration\n",
    "measurement_folder = '/media/al/Extreme SSD/20250701_usaf/20250425_0gan_single_reg_hs_usaf/test_latest/images'  # Update this path\n",
    "output_folder = '/media/al/Extreme SSD/20250701_usaf/deconvolution_results/batch_blind'\n",
    "measurement_pattern = '*.tif'  # Pattern for measurement files\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Blind deconvolution parameters\n",
    "balance = 3e-4  # Adjust this parameter as needed\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Find measurement files\n",
    "measurement_files = glob.glob(os.path.join(measurement_folder, measurement_pattern))\n",
    "print(f\"Found {len(measurement_files)} measurement files\")\n",
    "\n",
    "# Process each measurement file\n",
    "for meas_file in measurement_files:\n",
    "    print(f\"\\nProcessing: {meas_file}\")\n",
    "    \n",
    "    # Load the measurement image stack\n",
    "    measurement_stack = tifffile.imread(meas_file)\n",
    "    print(f\"Measurement stack shape: {measurement_stack.shape}\")\n",
    "    \n",
    "    # Process first 30 channels\n",
    "    num_channels = min(30, measurement_stack.shape[0])\n",
    "    \n",
    "    # Prepare output stack\n",
    "    deconv_stack = np.zeros_like(measurement_stack[:num_channels])\n",
    "    \n",
    "    for channel in range(num_channels):\n",
    "        print(f\"Processing channel {channel + 1}/{num_channels}\")\n",
    "        \n",
    "        # Extract single channel\n",
    "        measurement_image = measurement_stack[channel, :, :]\n",
    "        measurement_image = measurement_image / measurement_image.max()  # Normalize\n",
    "        \n",
    "        try:\n",
    "            # Perform blind deconvolution\n",
    "            deconv_result = rdmpy.blind(measurement_image, device=device, process=True, balance=balance)\n",
    "            \n",
    "            # Store result\n",
    "            deconv_stack[channel] = deconv_result.cpu().numpy() if torch.is_tensor(deconv_result) else deconv_result\n",
    "            \n",
    "            print(f\"  Successfully deconvolved channel {channel}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing channel {channel}: {str(e)}\")\n",
    "            # Use original image if deconvolution fails\n",
    "            deconv_stack[channel] = measurement_image\n",
    "            continue\n",
    "    \n",
    "    # Save deconvolved stack\n",
    "    base_name = Path(meas_file).stem\n",
    "    output_file = os.path.join(output_folder, f\"{base_name}_blind_deconvolved.tif\")\n",
    "    \n",
    "    # Save as 32-bit float to preserve dynamic range\n",
    "    tifffile.imwrite(output_file, deconv_stack.astype(np.float32))\n",
    "    print(f\"Saved blind deconvolved stack to: {output_file}\")\n",
    "    \n",
    "    # Optional: Save individual channels as PNG for visualization\n",
    "    png_folder = os.path.join(output_folder, f\"{base_name}_blind_channels\")\n",
    "    os.makedirs(png_folder, exist_ok=True)\n",
    "    \n",
    "    for channel in range(num_channels):\n",
    "        png_file = os.path.join(png_folder, f\"channel_{channel:02d}.png\")\n",
    "        plt.imsave(png_file, deconv_stack[channel], cmap='gray')\n",
    "    \n",
    "    print(f\"Saved individual channel PNGs to: {png_folder}\")\n",
    "\n",
    "print(\"\\nBatch blind deconvolution processing completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdmpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
